(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{317:function(t,s,a){t.exports=a.p+"assets/img/token_keyword.bb7120a5.jpg"},318:function(t,s,a){t.exports=a.p+"assets/img/token_identifier.9ffe1cb5.jpg"},319:function(t,s,a){t.exports=a.p+"assets/img/token_integer_constant.8e0f592f.jpg"},320:function(t,s,a){t.exports=a.p+"assets/img/token_floating_constant.8bbb60ff.jpg"},321:function(t,s,a){t.exports=a.p+"assets/img/token_character_constant.7caa77d6.jpg"},322:function(t,s,a){t.exports=a.p+"assets/img/token_string_literal.b4ff89a9.jpg"},323:function(t,s,a){t.exports=a.p+"assets/img/token_defualt.106ff759.jpg"},384:function(t,s,a){t.exports=a.p+"assets/img/pp_process.90452af8.jpg"},385:function(t,s,a){t.exports=a.p+"assets/img/pp_input.1f683304.jpg"},386:function(t,s,a){t.exports=a.p+"assets/img/pp_output.007a5a59.jpg"},387:function(t,s,a){t.exports=a.p+"assets/img/scanner_process.d53effcf.jpg"},388:function(t,s,a){t.exports=a.p+"assets/img/scanner_input_keyword.0b8a3f0b.jpg"},389:function(t,s,a){t.exports=a.p+"assets/img/scanner_output_keywords.4840f5c8.jpg"},390:function(t,s,a){t.exports=a.p+"assets/img/scanner_input_identifier.be91c9bd.jpg"},391:function(t,s,a){t.exports=a.p+"assets/img/scanner_output_identifier.11060f8e.jpg"},392:function(t,s,a){t.exports=a.p+"assets/img/scanner_input_integer.5aaf89ee.jpg"},393:function(t,s,a){t.exports=a.p+"assets/img/scanner_output_integer.15e5e721.jpg"},394:function(t,s,a){t.exports=a.p+"assets/img/scanner_input_float.a2706b72.jpg"},395:function(t,s,a){t.exports=a.p+"assets/img/scanner_output_float.93d899cd.jpg"},396:function(t,s,a){t.exports=a.p+"assets/img/scanner_input_char.284205c0.jpg"},397:function(t,s,a){t.exports=a.p+"assets/img/scanner_output_char.9021fc7a.jpg"},398:function(t,s,a){t.exports=a.p+"assets/img/scanner_input_string.3c985d58.jpg"},399:function(t,s,a){t.exports=a.p+"assets/img/string_output_string.46cef150.jpg"},494:function(t,s,a){"use strict";a.r(s);var n=a(25),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"lab3-词法分析实验"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#lab3-词法分析实验"}},[t._v("#")]),t._v(" lab3 词法分析实验")]),t._v(" "),n("h2",{attrs:{id:"_1-实验目的和内容"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-实验目的和内容"}},[t._v("#")]),t._v(" 1. 实验目的和内容")]),t._v(" "),n("p",[n("strong",[t._v("实验目的：")])]),t._v(" "),n("ul",[n("li",[t._v("熟悉 C 语言的词法规则，了解编译器词法分析器的主要功能和实现技术。")]),t._v(" "),n("li",[t._v("了解 Flex 工作原理和基本思想，学习使用工具自动生成词法分析器")]),t._v(" "),n("li",[t._v("掌握编译器从前端到后端各个模块的工作原理")]),t._v(" "),n("li",[t._v("掌握词法分析模块与其他模块之间的交互过程")]),t._v(" "),n("li",[t._v("学习正则表达式")])]),t._v(" "),n("p",[n("strong",[t._v("实验内容")]),t._v("：")]),t._v(" "),n("ul",[n("li",[t._v("安装 Flex")]),t._v(" "),n("li",[t._v("学习 Flex 的基本用法")]),t._v(" "),n("li",[t._v("编写预处理器\n"),n("ul",[n("li",[t._v("编写 Flex 的自定义代码部分")]),t._v(" "),n("li",[t._v("编写 Flex 的规则部分")])])]),t._v(" "),n("li",[t._v("编写词法分析器\n"),n("ul",[n("li",[t._v("编写 Flex 的自定义代码部分")]),t._v(" "),n("li",[t._v("编写 Flex 的规则部分")])])])]),t._v(" "),n("h2",{attrs:{id:"_2-实现的具体过程和步骤"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-实现的具体过程和步骤"}},[t._v("#")]),t._v(" 2. 实现的具体过程和步骤")]),t._v(" "),n("h3",{attrs:{id:"_2-1-安装-flex"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-安装-flex"}},[t._v("#")]),t._v(" 2.1 安装 Flex")]),t._v(" "),n("p",[t._v("实验环境为 Ubuntu 20.04.2.0，安装比较简单，直接输入命令：")]),t._v(" "),n("div",{staticClass:"language-shell extra-class"},[n("pre",{pre:!0,attrs:{class:"language-shell"}},[n("code",[t._v("$ "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("sudo")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("apt")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" flex\n")])])]),n("h3",{attrs:{id:"_2-2-学习-flex-的基本用法"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-学习-flex-的基本用法"}},[t._v("#")]),t._v(" 2.2 学习 Flex 的基本用法")]),t._v(" "),n("p",[t._v("flex 的 .l 文件由三部分组成：")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("definitions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义部分")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("rules"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\t\t\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 规则部分")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("user subroutines"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用户自定义代码部分")]),t._v("\n")])])]),n("ul",[n("li",[n("p",[t._v("定义部分格式一般为：")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[t._v("name definition\n")])])]),n("p",[t._v("其中，name 是名字，definition 是任意正则表达式。作用便是给用到的正则表达式去一个别名。")])]),t._v(" "),n("li",[n("p",[t._v("规则部分格式一般为：")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[t._v("pattern "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("action"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("其中，pattern 是正则表达式，action 是要执行的具体操作——即一段 C 代码。")])]),t._v(" "),n("li",[n("p",[t._v("用户子程序部分：")]),t._v(" "),n("p",[t._v("这部分代码会被拷贝到 lex.yy.c 中，用户可以把 main 函数写到其中。")])])]),t._v(" "),n("h3",{attrs:{id:"_2-3-编写预处理器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-编写预处理器"}},[t._v("#")]),t._v(" 2.3 编写预处理器")]),t._v(" "),n("p",[t._v("目前预处理器将要实现的功能包括：")]),t._v(" "),n("ul",[n("li",[t._v("去掉单行注释")]),t._v(" "),n("li",[t._v("去掉多行注释")]),t._v(" "),n("li",[t._v("处理多余的空格")])]),t._v(" "),n("h4",{attrs:{id:"_2-3-1-编写用户自定义代码部分"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-1-编写用户自定义代码部分"}},[t._v("#")]),t._v(" 2.3.1 编写用户自定义代码部分")]),t._v(" "),n("p",[t._v("首先编写 Flex 的自定义代码部分：")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" argc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("char")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("argv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  yyin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fopen")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1_scan_test.c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"r"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  yyout "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fopen")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1_scan_test.pp.c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("yylex")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("yywrap")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回值为 1，只处理单个文件")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("ul",[n("li",[n("p",[n("code",[t._v("yyin")]),t._v(" 和 "),n("code",[t._v("yyout")]),t._v(" 原本指向标准输入输出，一般为键盘和控制台。这里让它们分别指向 "),n("code",[t._v("1_scan_test.c")]),t._v(" 文件和 "),n("code",[t._v("1_scan_test.pp.c")]),t._v(" 文件。")]),t._v(" "),n("p",[t._v("后续可以将这两个文件以 "),n("code",[t._v("argv[i]")]),t._v(" （i = 1, 2 ...）替换，达到从输入参数指定输入输出文件的效果。")])]),t._v(" "),n("li",[n("p",[n("code",[t._v("yywrap")]),t._v(" 的返回值大于 0，表示只处理单个文件。")])])]),t._v(" "),n("h4",{attrs:{id:"_2-3-2-编写规则部分"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-2-编写规则部分"}},[t._v("#")]),t._v(" 2.3.2 编写规则部分")]),t._v(" "),n("p",[t._v("然后编写规则部分：")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nMultilineComment "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("^")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nWhitespace "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),t._v(" \\t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("\n \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"//"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\t\t\t\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 单行注释")]),t._v("\n  isMeeted "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" true"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("char")]),t._v(" c "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("input")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\n'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    c "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("input")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 吃掉单行注释后的所有内容，包括 \\n")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("MultilineComment"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 多行注释")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* Do Nothing */")]),t._v("\n  isMeeted "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" true"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("input")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\t\t\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 吃掉多行注释结尾的 \\n")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Whitespace"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果没有注释，则多个空白处理为一个空白")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("isMeeted "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" false"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fprintf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("yyout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果有注释，则清空注释之后的空白符")]),t._v("\n  isMeeted "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" false"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),n("ul",[n("li",[t._v("处理单行注释：遇到 "),n("code",[t._v("//")]),t._v(" 之后一直往后读取，直到遇到 "),n("code",[t._v("\\n")]),t._v(" ，中间所有的内容（包括 "),n("code",[t._v("\\n")]),t._v("）均会被丢弃掉")]),t._v(" "),n("li",[t._v("处理多行注释：使用正则表达式匹配，读取多行注释后不会再做任何事情（相当于清除内容），最后再丢弃 "),n("code",[t._v("\\n")])]),t._v(" "),n("li",[t._v("处理多个空白符：凡是出现多个空白符均变为单个空白符")])]),t._v(" "),n("blockquote",[n("p",[t._v("需要注意的是，因为处理多个空白符和处理注释时会产生一些小冲突，所以我定义了一个 isMeeted 作为空白符和注释同时出现的标记。")]),t._v(" "),n("p",[t._v("isMeeted 的作用是：")]),t._v(" "),n("ul",[n("li",[t._v("如果没有注释，则按照正常的多个空白符的处理办法")]),t._v(" "),n("li",[t._v("如果有注释，则注释后的所有空白符均被清除")])])]),t._v(" "),n("h3",{attrs:{id:"_2-4-编写词法分析器"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-编写词法分析器"}},[t._v("#")]),t._v(" 2.4 编写词法分析器")]),t._v(" "),n("p",[t._v("目前词法分析器，主要识别的 token 类型有：")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("单词")]),t._v(" "),n("th",[t._v("token 类型")]),t._v(" "),n("th",[t._v("单词")]),t._v(" "),n("th",[t._v("token 类型")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[n("img",{attrs:{src:a(317),alt:""}})]),t._v(" "),n("td",[t._v("Keyword")]),t._v(" "),n("td",[n("img",{attrs:{src:a(318),alt:""}})]),t._v(" "),n("td",[t._v("Identifier")])]),t._v(" "),n("tr",[n("td",[n("img",{attrs:{src:a(319),alt:""}})]),t._v(" "),n("td",[t._v("IntegerConstant")]),t._v(" "),n("td",[n("img",{attrs:{src:a(320),alt:""}})]),t._v(" "),n("td",[t._v("FloatingConstant")])]),t._v(" "),n("tr",[n("td",[n("img",{attrs:{src:a(321),alt:""}})]),t._v(" "),n("td",[t._v("CharacterConstant")]),t._v(" "),n("td",[n("img",{attrs:{src:a(322),alt:""}})]),t._v(" "),n("td",[t._v("StringLiteral")])]),t._v(" "),n("tr",[n("td",[n("img",{attrs:{src:a(323),alt:""}})]),t._v(" "),n("td",[t._v("与单词表示一致")]),t._v(" "),n("td",[t._v("EOF（表示文件结束）")]),t._v(" "),n("td",[t._v("EOF")])])])]),t._v(" "),n("p",[t._v("输出的 token 格式为 "),n("code",[t._v("[@0,0:2='int',<'int'>,1:0]")])]),t._v(" "),n("ul",[n("li",[t._v("以@开头的数字表示 token 的序号")]),t._v(" "),n("li",[t._v("紧接着的 xx:xx 表示 token 文本对应的开始列和结束列")]),t._v(" "),n("li",[t._v("“=” 后面给出了这个范围之内 token 的具体文本")]),t._v(" "),n("li",[t._v("“<>”之内表示 token 的类型")]),t._v(" "),n("li",[t._v("最后一个数字对 xx:xx 表示起始行和起始列")])]),t._v(" "),n("h4",{attrs:{id:"_2-4-1-编写用户自定义代码部分"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-1-编写用户自定义代码部分"}},[t._v("#")]),t._v(" 2.4.1 编写用户自定义代码部分")]),t._v(" "),n("p",[t._v("这部分代码和 2.3.1 的代码变化不大，只是输入文件变为了 "),n("code",[t._v("1_scan_test.pp.c")]),t._v("，输出文件变为了 "),n("code",[t._v("1_scanner_test.tokens")]),t._v("。")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" argc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("char")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("argv"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  yyin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fopen")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1_scan_test.pp.c"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"r"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  yyout "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fopen")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1_scanner_test.tokens"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("yylex")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("yywrap")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 返回值为 1, 只处理单个文件")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("h4",{attrs:{id:"_2-4-2-编写定义部分"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-2-编写定义部分"}},[t._v("#")]),t._v(" 2.4.2 编写定义部分")]),t._v(" "),n("p",[t._v("将定义部分分为两部分：")]),t._v(" "),n("p",[t._v("下面是第一部分：")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("option yylineno\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token macro property"}},[n("span",{pre:!0,attrs:{class:"token directive-hash"}},[t._v("#")]),n("span",{pre:!0,attrs:{class:"token directive keyword"}},[t._v("include")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("<stdio.h>")])]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\t\t    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录 token 的数量")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录 token 开始时 列 的位置")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" columns_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录 token 结束时 列 的位置")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),n("ul",[n("li",[t._v("yylineno 由 flex 提供，记录了当前的行号，方便输出单词的开始行")]),t._v(" "),n("li",[t._v("words 用于记录 token 列的位置，方便输出 token 的序号")]),t._v(" "),n("li",[t._v("columns_begin 和 columns_end 记录开始列和结束列")])]),t._v(" "),n("p",[t._v("下面是第二部分：")]),t._v(" "),n("ul",[n("li",[n("p",[t._v("首先匹配关键字，为这些关键字取一个别名 "),n("code",[t._v("Keyword")]),t._v("，这是定义部分")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("Keyword")]),t._v("\t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("auto")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("char")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("default")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("do")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("double")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("enum")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extern")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("float")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("goto")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("inline")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("long")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("register")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("restrict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("short")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("signed")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("sizeof")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("struct")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("switch")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typedef")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("union")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("unsigned")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("volatile")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),n("p",[t._v("接下来是规则部分，每匹配一个关键字，token 计数加 1，并把对应的信息输出到文件中：")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("Keyword"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\t\t\t\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 匹配关键字")]),t._v("\n  words"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  columns_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" yyleng"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fprintf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("yyout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"[@%d,%d:%d='%s',<'Keyword'>,%d:%d]\\n\"")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_begin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" yytext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" yylineno"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_begin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" columns_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])])]),t._v(" "),n("li",[n("p",[t._v("然后是匹配标识符，C 语言标识符由字母或者下划线开头，之后由字母、数字和下划线组成。给标识符定义别名 "),n("code",[t._v("Identifier")])]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nDigit\t\t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nNonDigit\t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("A"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("Za"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("z_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nIdentifier\t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("NonDigit"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("A"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("Za"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("z0"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("9")]),t._v("_"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n")])])]),n("p",[t._v("接下来是规则部分，和 KeyWords 部分类似，只是输出的类型变为 "),n("code",[t._v("Identifier")])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("{Identifier} {\n  ...\n  fprintf(yyout, \"[@%d,%d:%d='%s',<'Identifier'>,%d:%d]\\n\", words, columns_begin, columns_end, yytext, yylineno, columns_begin);\n  ...\n}\n")])])])]),t._v(" "),n("li",[n("p",[t._v("接着匹配整数，整数包括十进制、八进制和十六进制整数，并且还有 "),n("code",[t._v("u")]),t._v("、"),n("code",[t._v("U")]),t._v("、"),n("code",[t._v("l")]),t._v("、"),n("code",[t._v("L")]),t._v("、"),n("code",[t._v("ll")]),t._v("、"),n("code",[t._v("LL")]),t._v(" 等后缀")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("...\nNonzeroDigit\t\t[1-9]\nDecimalConstant\t    {NonzeroDigit}{Digit}*\n\nOctalDigit\t\t    [0-7]\nOctalConstant\t\t0{OctalDigit}*\n\nHexadecimalDigit\t[0-9a-fA-F]\nHexadecimalPrefix\t(0x)|(0X)\nHexdecimalConstant\t{HexadecimalPrefix}{HexadecimalDigit}*\n\nUnsignedSuffix\t\t(u)|(U)\nLongSuffix\t\t    (l)|(L)\nLongLongSuffix\t\t(ll)|(LL)\nIntergerSuffix\t\t{UnsignedSuffix}|{LongSuffix}|{LongLongSuffix}\n\nIntegerConstant\t({DecimalConstant}|{OctalConstant}|{HexdecimalConstant}){IntergerSuffix}?\n...\n")])])]),n("p",[t._v("接下来是规则部分，和 "),n("code",[t._v("Keyword")]),t._v(" 类似，只是输出的类型变为了 "),n("code",[t._v("IntegerConstant")])])]),t._v(" "),n("li",[n("p",[t._v("紧接着匹配浮点数，浮点数包括十进制和十六进制，且可以采用科学计数法，十进制是科学计数法的标志是 "),n("code",[t._v("e")]),t._v(" 或者 "),n("code",[t._v("E")]),t._v("，十六进制时科学计数法的标志是 "),n("code",[t._v("p")]),t._v(" 或者 "),n("code",[t._v("P")])]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("...\nSign\t\t\t    (\\+)|(\\-)\nExponentPart\t\t(e|E){Sign}{Digit}+\nFractionalConstant\t{Digit}+(\\.){Digit}+\n\nBinaryExponentPart\t(p|P){Sign}{Digit}+\nHexadecimalFractionalConstant\t{HexadecimalDigit}+(\\.){HexadecimalDigit}+\n\nFloatingSuffix\t\t(f)|(l)|(F)|(L)\n\nDecimalFloatingConstant\t({FractionalConstant}{ExponentPart}){FloatingSuffix}?\nHexadecimalFloatingConstant\t{HexadecimalPrefix}{HexadecimalFractionalConstant}{BinaryExponentPart}{FloatingSuffix}?\n\nFloatingConstant\t{DecimalFloatingConstant}|{HexadecimalFloatingConstant}\n...\n")])])]),n("p",[t._v("接下来是规则部分，和 "),n("code",[t._v("Keyword")]),t._v(" 类似，只是输出的类型变为了 "),n("code",[t._v("FloatingConstant")])])]),t._v(" "),n("li",[n("p",[t._v("之后是匹配字符，字符包括普通字符比如 "),n("code",[t._v("a")]),t._v("、"),n("code",[t._v("b")]),t._v(" 还有特殊字符，比如 "),n("code",[t._v("\\n")]),t._v(" 、"),n("code",[t._v("\\t")]),t._v(" 等。且字符由 "),n("code",[t._v("L")]),t._v(" 、"),n("code",[t._v("u")]),t._v("、"),n("code",[t._v("U")]),t._v(" 等前缀")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v("...\nCommonCharacters\t(\\').(\\')\nSpecialCharacters\t(\\')(\\\\).(\\')\nCharacterPrefix\t(L)|(u)|(U)\nCharacterConstant\t{CharacterPrefix}?{CommonCharacters}|{SpecialCharacters}\n...\n")])])]),n("p",[t._v("接下来是规则部分，和 "),n("code",[t._v("Keyword")]),t._v(" 类似，只是输出类型变为了 "),n("code",[t._v("CharacterConstant")])])]),t._v(" "),n("li",[n("p",[t._v("然后是匹配字符串，字符串有着 "),n("code",[t._v("L")]),t._v("、"),n("code",[t._v("u")]),t._v("、"),n("code",[t._v("U")]),t._v(" 和 "),n("code",[t._v("u8")]),t._v(" 等前缀。")]),t._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[t._v('CommonString\t\t\\"(\\\\.|[^"\\\\])*\\"\nStringPrefix\t\t(L)|(u)|(U)|(u8)\nStringLiteral\t\t{CommonString}\n')])])]),n("p",[t._v("接下来是规则部分，和 "),n("code",[t._v("Keyword")]),t._v(" 类似，只是输出类型变为了 "),n("code",[t._v("StringLiteral")])])]),t._v(" "),n("li",[n("p",[t._v("对于文件结束 "),n("code",[t._v("<<EOF>>")]),t._v("，需要特殊处理，使其返回值为 0，以免重复执行。")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<")]),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("EOF")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">>")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  words"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  columns_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" yyleng"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fprintf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("yyout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"[@%d,%d:%d='<EOF>',<EOF>,%d:%d]\\n\"")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_begin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" yylineno"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_begin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" columns_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])]),t._v(" "),n("li",[n("p",[t._v("至于没有匹配到的符号，基本都是运算符和界限符，则保持原样输出")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\t\t\t\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 之前没有匹配的符号，则保持原本的样子")]),t._v("\n  words"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  columns_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" yyleng"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("fprintf")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("yyout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"[@%d,%d:%d='%s',<'%s'>,%d:%d]\\n\"")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_begin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" yytext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" yytext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" yylineno"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns_begin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" columns_end"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])]),t._v(" "),n("li",[n("p",[t._v("此外为了准确记录列号，每次换行时，都需要将 "),n("code",[t._v("columns_begin")]),t._v(" 和 "),n("code",[t._v("columns_end")]),t._v(" 清零")]),t._v(" "),n("div",{staticClass:"language-c extra-class"},[n("pre",{pre:!0,attrs:{class:"language-c"}},[n("code",[t._v("\\n "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\t\t\t\t\t"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 换行，每次换行之后则重新计算 列 的位置")]),t._v("\n  columns_begin "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  columns_end "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])]),t._v(" "),n("h2",{attrs:{id:"_3-运行效果截图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-运行效果截图"}},[t._v("#")]),t._v(" 3. 运行效果截图")]),t._v(" "),n("p",[t._v("下面将运行效果截图分为两部分，第一部分是 flex 编译文件的过程，第二部分是输入文件和输出文件的对比。")]),t._v(" "),n("h3",{attrs:{id:"_3-1-预处理运行效果截图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-预处理运行效果截图"}},[t._v("#")]),t._v(" 3.1 预处理运行效果截图")]),t._v(" "),n("p",[n("strong",[t._v("flex 编译文件的过程")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(384),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("输入文件和输出文件的对比")])]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("输入文件")]),t._v(" "),n("th",[t._v("输出文件")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[n("img",{attrs:{src:a(385),alt:""}})]),t._v(" "),n("td",[n("img",{attrs:{src:a(386),alt:""}})])])])]),t._v(" "),n("p",[t._v("可以看到预处理将单行注释、多行注释和多余空格都处理。")]),t._v(" "),n("h3",{attrs:{id:"_3-2-词法分析运行效果截图"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-词法分析运行效果截图"}},[t._v("#")]),t._v(" 3.2 词法分析运行效果截图")]),t._v(" "),n("p",[n("strong",[t._v("flex 编译文件的过程")])]),t._v(" "),n("p",[n("img",{attrs:{src:a(387),alt:""}})]),t._v(" "),n("p",[n("strong",[t._v("输入输出文件的对比")])]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("规则")]),t._v(" "),n("th",[t._v("输入文件")]),t._v(" "),n("th",[t._v("输出文件")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[t._v("Keyword")]),t._v(" "),n("td",[n("img",{attrs:{src:a(388),alt:""}})]),t._v(" "),n("td",[n("img",{attrs:{src:a(389),alt:""}})])]),t._v(" "),n("tr",[n("td",[t._v("Identifier")]),t._v(" "),n("td",[n("img",{attrs:{src:a(390),alt:""}})]),t._v(" "),n("td",[n("img",{attrs:{src:a(391),alt:""}})])]),t._v(" "),n("tr",[n("td",[t._v("IntegerConstant")]),t._v(" "),n("td",[n("img",{attrs:{src:a(392),alt:""}})]),t._v(" "),n("td",[n("img",{attrs:{src:a(393),alt:""}})])]),t._v(" "),n("tr",[n("td",[t._v("FloatingConstant")]),t._v(" "),n("td",[n("img",{attrs:{src:a(394),alt:""}})]),t._v(" "),n("td",[n("img",{attrs:{src:a(395),alt:""}})])]),t._v(" "),n("tr",[n("td",[t._v("CharacterConstant")]),t._v(" "),n("td",[n("img",{attrs:{src:a(396),alt:""}})]),t._v(" "),n("td",[n("img",{attrs:{src:a(397),alt:""}})])]),t._v(" "),n("tr",[n("td",[t._v("StringLiteral")]),t._v(" "),n("td",[n("img",{attrs:{src:a(398),alt:""}})]),t._v(" "),n("td",[n("img",{attrs:{src:a(399),alt:""}})])])])]),t._v(" "),n("h2",{attrs:{id:"_4-实验心得体会"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_4-实验心得体会"}},[t._v("#")]),t._v(" 4. 实验心得体会")]),t._v(" "),n("p",[t._v("这次的词法分析实验，因为实现方式众多，我也尝试了好几种方式，最终采用 Flex 来完成实验。和其他方式相比，Flex 更加方便快捷，修改也很方便。")]),t._v(" "),n("p",[t._v("在实验过程中，我更加熟悉了正则表达式的书写，深感正则表达式简明而不简单。同样的单词可以用多种正则式来识别，不同正则式之间差别很大，可读性的相差也很大。")]),t._v(" "),n("p",[t._v("当然，在书写正则表达式时，我不可避免地对一些边界情况没有考虑清楚，这也导致我的词法分析器虽然能够识别大部分单词，但偶尔会有一些遗漏之处。这些都需要我之后再一一完善。")]),t._v(" "),n("blockquote",[n("p",[t._v("备注：本实验在虚拟机的 Ubuntu20.04.2.0 完成，由于我虚拟机出了些问题，能够复制粘贴文本却无法复制粘贴文件，所以 bin 目录下的 exe 文件是在 Windows 10 下重新编译 pp.lex.yy.c 文件和 scannner.lex.yy.c 文件得到的。")])])])}),[],!1,null,null,null);s.default=e.exports}}]);